{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`Twitter Scraper`](https://github.com/bisguzar/twitter-scraper) is a `Python` library that lets you collect Twitter data without using the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from twitter_scraper import get_tweets\n",
    "from twitter_scraper import Profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file [twitter_accounts.csv](./data/twitter_accounts.csv) in the `data` folder of this repository contains a few Twitter screen names which we will use in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = pd.read_csv('data/twitter_accounts.csv')\n",
    "accounts = accounts['Screen Name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following code we collect the profile information for the accounts from the list we imported before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_info = []\n",
    "for account in accounts:\n",
    "    profile = Profile(account)\n",
    "    profile = profile.to_dict()\n",
    "    account_info.append(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can transform this list of dictionaries into a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_info_df = pd.DataFrame(account_info)\n",
    "account_info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to, you can export this dataframe as a `CSV` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_info_df.to_csv('data/account_info_ts.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `Twitter Scraper` to collect the tweets from specific accounts. The `pages` parameter specifies how many pages of results you want (although the frontend of [Twitter Search](https://twitter.com/explore) continuously loads additional results, they are still divided into pages in the backend). If you want more tweets, you can increase the number of `pages` or leave out that parameter in the `get_tweets()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_tweets = []\n",
    "for account in accounts:\n",
    "    for tweet in get_tweets(account, pages=1): #increase the number of pages of remove the 'pages' parameter if you want to collect more tweets\n",
    "        account_tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, again, convert the resulting list of dictionaries to a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_tweets_df = pd.DataFrame(account_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we export the dataframe it helps to split up the `entries` column that contains dictionaries into separate columns that contain (comma-separated) strings. You may receive an error message when running the code cell below, if one of the resulting columns (e.g., the `video` column) does not contain any values (in which case you can safely ignore the error message)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_tweets_df = pd.concat([account_tweets_df.drop(['entries'], axis=1), account_tweets_df['entries'].apply(pd.Series)], axis=1)\n",
    "account_tweets_df['hashtags'] = account_tweets_df['hashtags'].apply(', '.join)\n",
    "account_tweets_df['urls'] = account_tweets_df['urls'].apply(', '.join)\n",
    "account_tweets_df['photos'] = account_tweets_df['photos'].apply(', '.join)\n",
    "account_tweets_df['videos'] = account_tweets_df['videos'].apply(', '.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if everything worked, you can have a look at the first 5 rows of the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can store the resulting dataframe as a `CSV` file in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_tweets_df.to_csv('data/tweets_ts.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
