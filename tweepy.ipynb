{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tweepy` library has a really good [documentation](http://docs.tweepy.org/en/latest/) that you should check out if you want to use it.\n",
    "\n",
    "The examples in this notebook are adapted from the workshop [*Fundamentals of Data Analysis with Python*](https://github.com/mclevey/GESIS_2020_Fundamentals) by [John McLevey](https://github.com/mclevey) and [Jilian Anderson](https://github.com/jillianderson8)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use `tweepy` you need to have registered a Twitter application. Once you have done so, you can find the necessary information in the *Keys & Tokens* menu for your app. If you need some guidance/reminder on where to find that information, you can have a look at the documentation of the `rwteet` package which has a [section on this topic](https://rtweet.info/articles/auth.html). Keep in mind that the layout of the Twitter developer pages might change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: You should treat all information relating to your API key like a password and never share it or post it publicly anywhere.\n",
    "For the purpose of this notebook, we will store the keys in a separate file. To do this, simply open the file [config_twitter.py](./config_twitter.py), enter the information for your app, and save the file by pressing CTRL + S (Windows) or CMD + S (MacOS). After that you can run the code cell below to import the file and authenticate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although nobody except you should be able to access your personal instance of this notebook (and your edits will also not be persistent if you do not have/use a *GESIS Notebooks* user account), if you want to be extra cautious, you can delete your API access information from the [config_twitter.py file](./config_twitter.py) (and save the file again) after running the following cell once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config_twitter\n",
    "\n",
    "auth = tweepy.OAuthHandler(config_twitter.API_KEY, config_twitter.API_KEY_SECRET)\n",
    "auth.set_access_token(config_twitter.ACCESS_TOKEN, config_twitter.ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, compression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments `wait_on_rate_limit=True` and `wait_on_rate_limit_notify=True` enable `Tweepy` to make sure that we stay within the Twitter API rate limits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `REST API`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file [twitter_accounts.csv](./data/twitter_accounts.csv) in the `data` folder of this repository contains a few Twitter screen names which we will use in the following examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = pd.read_csv('data/twitter_accounts.csv')\n",
    "accounts = accounts['Screen Name'].tolist()\n",
    "accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we collect information about the accounts we may first want to retrieve the user IDs. The reason for this is that screen names can change, whereas user IDs remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [api.get_user(i) for i in accounts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the user IDs to gather the account information. We will store the results as a [`pandas`](https://pandas.pydata.org/) dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_info = [[i.name, i.screen_name, i.id, i.description, i.location, i.followers_count, i.friends_count, i.protected] for i in ids]\n",
    "account_info = pd.DataFrame(account_info, columns = ['Name', 'Handle', 'Twitter ID Number', 'Description', 'Location', 'Number of Followers', 'Follows', 'Protected'])\n",
    "account_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to, you can store the result as a `CSV` file by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_info.to_csv('data/twitter_accounts_workshop_orgs.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accounts followed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve a list of (up to 5000) accounts a user follows. In the following function we, again, use the Twitter User ID instead of the screen name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_followed(user_id):\n",
    "    friends = []\n",
    "    cursor = tweepy.Cursor(api.friends_ids, id=user_id, count=5000) \n",
    "    for page in cursor.pages():\n",
    "        for friend in page:\n",
    "            friends.append(friend)\n",
    "    return friends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this function to collect the IDs of all the users followed by *@gesis_org*. From our previous call to the `REST API` we know that the User ID for the *GESIS* account is 145554242."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesis_followed = get_followed('145554242')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gesis_followed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these IDs to collect information about these accounts. We could, of course, do this for all accounts followed by *@gesis_org*. However, this would take some time and we might hit our Twitter API rate limit with this. Hence, we'll just do this for the first 10 accounts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesis_followed_test = gesis_followed[:10]\n",
    "\n",
    "gesis_followed_info = [api.get_user(i) for i in gesis_followed_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now turn the result into a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesis_followed_info_cut = [[i.name, i.screen_name, i.id, i.description, i.location, i.followers_count, i.friends_count, i.protected] for i in gesis_followed_info]\n",
    "pd.DataFrame(gesis_followed_info_cut, columns = ['Person', 'Handle', 'Twitter ID Number', 'Description', 'Location', 'Number of Followers', 'Follows', 'Protected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical tweets & metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines the function `get_tweet_data` that takes a screen name and requests the tweets from the user timeline via the Twitter REST API. It also collects some of the metadata for each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet_data(user, user_meta=False):\n",
    "    tweets = []\n",
    "    \n",
    "    for tw in tweepy.Cursor(api.user_timeline, screen_name=user, exclude_replies=False, count = 200, tweet_mode = 'extended').items():\n",
    "        tdict = {}\n",
    "        \n",
    "        tdict['text'] = tw.full_text.replace('\\n', '').strip() # remove newline tags + leading and trailing whitespace    \n",
    "        tdict['tweet_id'] = tw.id\n",
    "        tdict['retweet_count'] = tw.retweet_count\n",
    "        tdict['fav_count'] = tw.favorite_count\n",
    "        tdict['user_id'] = tw.user.id        \n",
    "        tdict['user_screen_name'] = tw.user.screen_name\n",
    "        tdict['time'] = tw.created_at\n",
    "        tdict['hashtags'] = [hashtag['text'] for hashtag in tw.entities['hashtags']]\n",
    "        tdict['user_mentions'] = [user['screen_name'] for user in tw.entities['user_mentions']]\n",
    "        \n",
    "        if user_meta is True:\n",
    "            tdict['location'] = tw.user.location\n",
    "            tdict['user_description'] = tw.user.description\n",
    "            tdict['user_url'] = tw.user.url \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        tweets.append(tdict)\n",
    "    \n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this function to collect historical tweets (+ some metadata) for the accounts from our list. Note that running the next cell might take a few seconds. As the resulting objects is a list of lists, we need to flatten it before we can create a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_tweets = [get_tweet_data(i) for i in accounts]\n",
    "\n",
    "account_tweets = [y for x in account_tweets for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_tweets_df = pd.DataFrame(account_tweets)\n",
    "\n",
    "account_tweets_df['hashtags'] = account_tweets_df['hashtags'].apply(', '.join)\n",
    "account_tweets_df['user_mentions'] = account_tweets_df['user_mentions'].apply(', '.join)\n",
    "\n",
    "account_tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, if you want to, you can store the result as a `CSV` file by executing the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_tweets_df.to_csv('data/tweets_tweepy.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `Streaming API`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use `tweepy` to collect data from the Twitter `Streaming API`, you need to set up a `StreamListener`. If you want to learn more about this, you can read the [corresponding section of the `tweepy` documentation](http://docs.tweepy.org/en/latest/streaming_how_to.html). The `MyStreamListener` defined in the cell below will collect data from the `STREAM API` for 10 seconds and append new tweet data to a file called `tweepy_stream.csv`, which is stored in the `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEP = ';'\n",
    "csv = open('data/tweepy_stream.csv', 'a', encoding='utf-8')\n",
    "csv.write('Date' + SEP + 'Tweet' + SEP + 'Number of Followers' + SEP + 'Follows' + SEP + 'Handle' + '\\n')\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, time_limit=10): # you can set the default timeout for this StreamListener here (in seconds)\n",
    "        self.start_time = time.time()\n",
    "        self.limit = time_limit\n",
    "        super(MyStreamListener, self).__init__()\n",
    "\n",
    "    def on_status(self, status):\n",
    "        if (time.time() - self.start_time) < self.limit:\n",
    "            if hasattr(status, 'retweeted_status'):\n",
    "                try:\n",
    "                    tweet = status.retweeted_status.extended_tweet[\"full_text\"]\n",
    "                except:\n",
    "                    tweet = status.retweeted_status.text\n",
    "            else:\n",
    "                try:\n",
    "                    tweet = status.extended_tweet[\"full_text\"]\n",
    "                except AttributeError:\n",
    "                    tweet = status.text\n",
    "        \n",
    "            date = status.created_at.strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "            follower = str(status.user.followers_count)\n",
    "            friend = str(status.user.friends_count)\n",
    "            name = status.user.screen_name\n",
    "        \n",
    "            csv.write(date + SEP + tweet.strip().replace(\"\\n\",\"\").replace('\\r','').replace(';',',') + SEP + follower + SEP + friend + SEP + name + '\\n')\n",
    "            return True\n",
    "        else:\n",
    "            csv.close()\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you run the two following cells, you will start to stream all tweets mentioning \"COVID-19\" or \"Corona\" for 10 seconds. If you change the time limit and want to manually stop the data collection, you need to interrupt the `Python` kernel in this notebook. You can do so by clicking the square stop button in the notebook menu on top or by pressing the i-key on your keyboard twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener) # to change the duration of the collection, you can add the argument time_limit = value_in_seconds here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myStream.filter(track=['COVID-19', 'Corona'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the results by opening the [tweepy_stream.csv](./data/tweepy_stream.csv) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also stream tweets by specific users. To do this you need to provide an array of IDs to the `follow` parameter: `mystream.filter(follow=accounts)`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
